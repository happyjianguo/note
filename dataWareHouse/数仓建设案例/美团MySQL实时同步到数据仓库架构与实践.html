<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>美团MySQL实时同步到数据仓库架构与实践</title>
	</head>
<body>
<h1>美团MySQL实时同步到数据仓库架构与实践</h1>

<p><a href="https://mp.weixin.qq.com/s/GhBPkkW6Qucv0iARHvJ-Rg">[] https://mp.weixin.qq.com/s/GhBPkkW6Qucv0iARHvJ-Rg </a></p>

<p>美团的ODS层数据从MySQL等关系型数据库的业务数据进行采集，导入到Hive中。</p>

<p>过去导入的流程是直连MySQL去select表中的数据，存到本地文件作为中间存储，最后把文件Load到Hive表中。这样做有几个缺点：</p>

<ul>
	<li>随着业务规模的增长，select from mysql -&gt; save to localfile -&gt; load to hive这种数据流花费的时间越来越久，无法满足下游数仓生产的时间要求；</li>
	<li>从MySQL中select大量数据会对MySQL造成较大影响；</li>
	<li>由于Hive本身语法不支持更新、删除等sql原语，对于MySQL中发生update/delete的数据无法很好的进行支持</li>
</ul>

<p>因此，方案转向：CDC + Merge的解决方案，也就是：实时Binlog采集 + 离线处理Binlog还原业务数据这样一套解决方案。</p>

<hr />

<h2>整体架构</h2>

<figure><img src="/Users/xerxes/note/dataWareHouse/src/%E7%BE%8E%E5%9B%A2binlog%E5%90%8C%E6%AD%A5%E6%9E%B6%E6%9E%84.jpg"/></figure>

<p>Binlog实时采集方面，采用了阿里的开源项目Canal，负责从MySQL实时拉取Binlog并完成适当解析。</p>

<p>Binlog采集后会暂存到Kafka上供下游消费。</p>

<p>离线处理部分，通过以下步骤在Hive上还原一张MySQL表：</p>

<ol>
	<li>采用Linkedin的开源项目Camus，负责每小时把Kafka上的Binlog数据拉取到Hive；</li>
	<li>对每张ODS表，首先需要一次性制作快照，把MySQL里的存量数据读取到Hive上，这一过程底层采用直连MySQL去select数据的方式；</li>
	<li>对每张ODS表，每天基于存量数据和当天增量产生的Binlog做Merge，从而还原出业务数据</li>
</ol>

<p>这样做的好处：</p>

<ul>
	<li>Binlog流式产生，把部分数据处理需求从每天一次的批处理分摊到实时流上，提高性能，减轻对MySQL的压力；</li>
	<li>Binlog本身记录了数据变更的类型，通过一些语义方面的处理，精准还原数据</li>
</ul>

<hr />

<h2>Binlog实时采集</h2>

<p>Binlog实时采集包括两个主要模块：</p>

<ul>
	<li>CanalManager，主要负责采集任务的分配，监控报警、元数据管理和与外部依赖系统的对接；</li>
	<li>真正执行采集任务的Canal和CanalClient</li>
</ul>

<figure><img src="/Users/xerxes/note/dataWareHouse/src/%E7%BE%8E%E5%9B%A2Binlog%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B%E7%9A%84%E5%89%AF%E6%9C%AC.jpg"/></figure>

<ol>
	<li>用户提交某个DB的Binlog采集请求；</li>
	<li>CanalManager调用DBA平台相关接口获取这个DB再MySQL实例的相关信息，目的是从中选出最适合Binlog采集的机器；</li>
	<li>CanalManager考虑负载均衡、跨机房传输等因素，把采集实例Canal Instance分发到合适的Canal服务器，即Canal Server上；</li>
	<li>Canal Server收到采集请求，在zk上对收集信息进行注册，注册内容包括：

		<ul>
			<li>以Instance名称命名的永久节点；</li>
			<li>在该永久节点下注册以自身ip:port命名的临时节点</li>
		</ul>

		<p>这样做有两个目的：</p>

		<ul>
			<li>高可用：高可用：CanalManager对Instance进行分发时，会选择两台CanalServer，一台是Running节点，另一台作为Standby节点。Standby节点会对该Instance进行监听，当Running节点出现故障后，临时节点消失，然后Standby节点进行抢占。这样就达到了容灾的目的；</li>
			<li>与CanalClient交互：CanalClient检测到自己负责的Instance所在的Running CanalServer后，便会进行连接，从而接收到CanalServer发来的Binlog数据</li>
		</ul></li>
</ol>

<p>对Binlog的订阅以MySQL的DB为粒度，一个DB的Binlog对应了一个Kafka Topic。底层实现时，一个MySQL实例下所有订阅的DB，都由同一个Canal Instance进行处理。这是因为Binlog的产生是以MySQL实例为粒度的。CanalServer会抛弃掉未订阅的Binlog数据，然后CanalClient将接收到的Binlog按DB粒度分发到Kafka上。</p>

<hr />

<h2>离线还原MySQL数据</h2>

<p>完成Binlog采集，下一步就是把Binlog从Kafka同步到Hive，利用Binlog还原业务数据。</p>

<figure><img src="/Users/xerxes/note/dataWareHouse/src/%E7%BE%8E%E5%9B%A2Binlog%E7%A6%BB%E7%BA%BF%E8%BF%98%E5%8E%9FMySQL%E6%95%B0%E6%8D%AE.jpg"/></figure>

<h3>Kafka2Hive</h3>

<p>整个Kafka2Hive任务的管理，在美团数据平台的ETL框架下进行，包括任务原语的表达和调度机制等，都同其他ETL类似。</p>

<p>底层采用Camus，并进行二次开发。</p>

<h3>Merge</h3>

<p>Merge流程做了两件事</p>

<ol>
	<li>首先把当天生成的Binlog数据存放到Delta表中，然后和已有的存量数据做一个基于主键的Merge；</li>
	<li>Delta表中的数据是当天的最新数据，当一条数据在一天内发生多次变更时，Delta表中只存储最后一次变更后的数据</li>
</ol>

</body>
</html>

