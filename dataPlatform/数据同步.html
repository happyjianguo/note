<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>数据同步</title>
	</head>
<body>
<h1>数据同步</h1>

<hr />

<h3>直连同步</h3>

<p>指通过定义好的规范接口API和基于动态链接库的方式直接连接业务库，如JDBC等规定了统一规范的标准接口，不同的数据库基于这套标准接口提供规范的驱动，支持完全相同的函数调用和SQL实现。</p>

<p>优点：</p>

<ul>
	<li>配置简单，容易实现</li>
	<li>适合操作型业务系统的数据同步</li>
</ul>

<p>缺点</p>

<ul>
	<li>对源系统的性能影响较大</li>
	<li>如果业务库采取主备策略，则可以从备库抽取数据，避免对业务系统产生性能影响，但是当数据量较大时，采取此种抽取方式性能较差，不适合业务系统到数据仓库的同步</li>
</ul>

<hr />

<h3>数据文件同步</h3>

<p>通过约定好的文件编码、大小、格式等，直接从源系统生成数据的文本文件，由专门的文件服务器，如FTP服务器传输到目标系统后，加载到目标数据库系统中。</p>

<p>由于通过文件服务器上传，下载可能会造成丢包或错误，为了确保数据文件同步的完整性，通常还会上传一个校验文件，记录数据文件的数据量以及文件大小等校验信息，以供下游目标系统验证数据同步的准确性。还可以在从源系统生成数据文件的过程中增加压缩和加密功能。</p>

<hr />

<h3>数据库日志解析同步</h3>

<p>以Oracle为例，通过源系统的进程，读取归档日志文件用以收集变化的数据信息，并判断日志中的变更是否属于被收集对象，将其解析到目标数据文件中。数据文件传输到目标系统后，通过数据加载模块完成数据的导入，从而实现数据从源系统到目标系统的同步。</p>

<hr />

<h3>阿里解决方案</h3>

<h5>批量数据同步</h5>

<p>DataX是一个能满足多方向高自由度的异构数据交换服务产品。对于不同数据源，DataX通过插件的形式提供支持，将数据从数据源读出并转换为中间状态，同时维护好数据的传输、缓存等工作。</p>

<h5>实时数据同步</h5>

<p>业务系统产生的交易数据需要实时汇总，实现秒级的数据刷新时，可以通过解析mysql的binlog日志来实时获得增量的数据更新，并通过消息订阅模式来实现数据的实时同步。</p>

<h5>增量与全量同步的合并</h5>

<p>随着表的数据量增大，按周期全量同步会影响效率。这种情况下，可以选择每次只同步新变更的增量数据，然后与上一个同步周期获得的全量数据进行合并，从而获得最新版本的全量数据。</p>

<p>传统数据整合方案中，合并技术大多采用<strong>merge方式（insert+update）</strong>；但是当前流行的大数据平台基本上都不支持update操作，现在比较推荐的方式是<strong>全外连接（full outer join） + 数据全量覆盖重新加载（insert overwrite）</strong>。如果担心数据更新错误，可以采用分区方式，每天保持一个最新的全量版本，保留较短的时间周期（3-7天）。</p>

<h5>同步性能的处理</h5>

<p>数据同步任务是针对不同数据库系统之间的数据同步问题创建的一系列周期调度的任务。针对数据同步任务运行不稳定的问题阿里实践出了一套基于负载均衡思想的新型数据同步方案。核心思想是通过目标数据库的元数据估算同步任务的总线程数，以及通过系统预定义的期望同步速度估算首轮同步的线程数；同时通过数据同步任务的业务优先级决定同步线程的优先级，最终提升同步任务的执行效率和稳定性。</p>

<h5>数据漂移的处理</h5>

<blockquote>
<p>数据漂移通常是指ODS层的表的同一个业务日期数据中包含前一天或后一天凌晨附近的数据或者丢失当天的变更数据。</p>
</blockquote>

<p>由于ODS需要承接面向历史的细节数据查询需求，这就需要物理落地到数据仓库的ODS表按时间段来切分进行分区存储，通常的做法是按某些时间戳字段来切分，而实际上往往由于时间戳字段的准确性导致漂移。</p>

<p>通常，时间戳字段分为四类：</p>

<ul>
	<li>数据库表中用来标识数据记录更新时间的时间戳字段</li>
	<li>数据库日志中用来标识数据记录更新时间的时间戳字段</li>
	<li>数据库表中用来记录具体业务过程发生时间的时间戳字段</li>
	<li>标识数据记录被抽取到的时间的时间戳字段</li>
</ul>

<p>这几个事件理论上应该是一致的，但是实际生产中很多原因会导致这几个时间有差异。如果按照其中一个字段来切分ODS表，就会导致数据漂移：</p>

<ul>
	<li>根据extractTime，由于数据抽取是需要时间的，extractTime一般会比较晚，因此最容易发生漂移</li>
	<li>根据modifiedTime，如果前台业务系统手工订正数据时没有更新modifiedTime就会导致数据遗漏，或者凌晨时间产生的数据记录漂移到后一天</li>
	<li>根据logTime，由于网络或者系统压力问题，logTime晚于procTime，导致凌晨时间产生的数据记录漂移到后一天</li>
	<li>根据procTime，所获取的ODS表只是包含一个业务过程所产生的记录，会遗漏很多其他过程的变化记录，违背了ODS和业务系统保持一致的设计原则</li>
</ul>

<p>处理方法：</p>

<ol>
	<li>多获取后一天的数据

		<p>在ODS层每个时间分区中向前、向后多冗余一些数据，保障数据只会多不会少</p></li>
	<li>通过多个时间戳字段限制时间来获取相对准确的数据

		<p>首先根据logTime分别冗余前一天最后15分钟和后一天凌晨开始15分钟的数据，并用modifiedTime过滤非当天数据，确保数据不会因为系统问题遗漏；</p>

		<p>然后根据logTime获取后一天15分钟的数据，针对此数据，按照主键根据logTime做升序排列去重。因为我们需要获取的是最接近当天记录变化的数据（数据库日志保留所有变化的数据，但是落地到ODS层的是根据主键去重获取最后状态变化的数据）</p>

		<p>最后将前两步的结果数据做全外连接，通过限制业务时间procTime来获取需要的数据。</p></li>
</ol>

</body>
</html>

