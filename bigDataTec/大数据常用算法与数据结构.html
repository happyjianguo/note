<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>大数据常用算法与数据结构</title>
	</head>
<body>
<h1>大数据常用算法与数据结构</h1>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<hr />

<h3>步隆过滤器（Bloom Filter）</h3>

<p>由Howard Bloom在1970年提出的二进制向量数据结构，具有很好的空间和时间效率，尤其是空间效率极高，常被用来监测某个元素是否是巨量数据集合中的成员。</p>

<h5>基本原理</h5>

<p><strong>BF可以高效地表征集合数据，其使用长度为m的位数组来存储集合信息，同时使用k个相互独立的hash函数将数据映射到位数组空间</strong>。</p>

<p><strong>存储流程</strong>：</p>

<p>首先，将长度为m的位数组元素全部置为0。</p>

<p>对于集合S中的某个成员a，分别使用k个hash函数对其计算，如果$h_i(a)=x$，则将位数组的第x位置为1，对于成员a来说，经过k个hash函数计算后，会将位数组中的$w(w \leq k)$位置为1。</p>

<p>对于集合中的其他成员也如此处理，即可完成位数组空间的几何表示。</p>

<p><strong>查询流程</strong>：</p>

<p>查询某个成员a是否在集合S中出现时，使用相同的k个hash函数计算，如果其对应位数组中的w位都为1，则判断成员a属于集合S，只要w位中有任意一位为0，则判断成员a不属于集合S。</p>

<h5>误判率及相关计算</h5>

<p><strong>因为BF使用位数组和hash函数来表征集合，并不需要实际存储集合数据本身内容，所以其空间利用率非常高</strong>。</p>

<p>当BF查询某个不属于集合的元素时，经hash计算出的位上全是1，就会错误的判断这个元素属于集合，称为误判（False Positive）。<strong>因此BF智能使用在允许发生一定误判的场景</strong>。</p>

<p>尽管BF会产生误判，但是不会发生漏判（False Negative）。即如果某个成员属于集合，那么BF一定会判断其属于集合。</p>

<p>在实际应用中，一般希望可以在一定范围内控制误判率的大小，比如低于1%。<strong>影响误判率的因素包括：集合大小n，hash函数的个数k和位数组大小m</strong>。</p>

<p>Hash函数个数对误判率的影响情况比较复杂，一方面在将集合成员映射到位数组过程中，如果其他条件固定，使用的hash函数越多，则位数组会有更多的位被设置为1；但是查询时，hash函数越多，明显误判的可能性就越小。</p>

<p>3个因素与误判率的关系：</p>

$$ P_{fp} = (1- e^{-k\dfrac{n}{m}})^{k} $$
<p>最优的hash函数个数为：</p>

$$ k = \dfrac{m}{n}ln2 $$
<p>实际应用中，更常见的需求是假设已知集合大小n，并设定好误判率P，需要计算给BF分配多大内存合适，也就是确定m的大小：</p>

$$ m = -\dfrac{nlnp}{ln2}^2 $$
<h5>改进：计数Bloom Filter</h5>

<p>基本的BF在使用时有个缺点：无法删除集合成员，只能增加和查询。</p>

<p>计数BF的基本信息单元由多个比特位来表示，一般情况采取3-4比特位为单元。集合成员加入数组时，根据k个hash函数计算，此时对应位置的信息单元由多个比特位构成，所以将原先的数值加1即可。查询时，只要对应位置的信息单元都不为0即可认为该成员属于集合。删除时，只要将对应位置的计数减1即可。</p>

<hr />

<h3>SkipList</h3>

<p>由Wiliam Pugh于1990年提出，是一种可替代平衡树的数据结构，不像平衡树需要强制保持树的平衡，SkipList依靠随机生成数以一定概率保持数据的平衡分布。</p>

<p>插入、删除、查找数据的时间复杂度都是O(log(N))。除了高效外实现和维护也非常简单，所以在很多大数据系统中在维护有序列表高效读/写的场景下都会采用。</p>

<h5>核心思路</h5>

<p>对于传统的有序链表，如果需要查找其中某条数据，需要顺序遍历。如果链表中一半节点能够多保留一个指向后续节点之后节点的指针，那么此时最多遍历$\dfrac{n}{2}+1$次即可找到任意节点。</p>

<figure><img src="/Users/xerxes/note/bigDataTec/src/%E6%8C%87%E9%92%88%E8%B7%B3%E8%B7%83%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8.jpg"/></figure>

<p><strong>类似的，还可以给部分节点增加3、4个或者更多的指针，指向更远的后方节点，进一步提高查询效率。这就是SkipList的核心思路</strong>。</p>

<figure><img src="/Users/xerxes/note/bigDataTec/src/SkipList%E5%85%B8%E5%9E%8B%E7%BB%93%E6%9E%84.jpg"/></figure>

<p><strong>SkipLisdt依赖随机数来以一定概率保持数据的平衡</strong>。SkipList在插入节点的时候，随机决定该节点应该有多少个指向后续节点的指针，有几个指针就称这个节点是几层的。整个链表中最高层级用MaxLevel表示，链表的表头具有MaxLevel层级。</p>

<p><strong>查找流程</strong>：</p>

<figure><img src="/Users/xerxes/note/bigDataTec/src/SkipList%E6%9F%A5%E6%89%BE%E6%B5%81%E7%A8%8B.jpg"/></figure>

<p>从链表表头开始，顺序往后找到第一个大于或等于当前查找数值的节点；</p>

<p>找到之后后退到前一个节点，然后将第一层继续查找；</p>

<p>当在本层未找到时，就下降一个层级继续查找；</p>

<p>直到找到或者发现链表根本不包含查找的数值。</p>

<p><strong> 插入流程</strong>：</p>

<figure><img src="/Users/xerxes/note/bigDataTec/src/SkipList%E6%8F%92%E5%85%A5%E6%B5%81%E7%A8%8B.jpg"/></figure>

<p>从所有小于待插入节点key值的节点中，找出最大的那个；</p>

<p>创建新节点，并且产生一个在1～MAX-LEVEL之间的随机LEVEL值作为该节点的LEVEL；</p>

<p>调整指针指向</p>

<p><strong>移除流程</strong>：</p>

<figure><img src="SkipList%E7%A7%BB%E9%99%A4%E6%B5%81%E7%A8%8B.jpg"/></figure>

<p>查找到指定的节点；</p>

<p>调整指针指向；</p>

<p>释放节点空间</p>

<hr />

<h3>Snappy与LZSS算法</h3>

<p>Snappy是Google开源出的高效数据压缩与解压算法库，目标并非是最高的数据压缩率，而是在合理的压缩率基础上追求尽可能快的压缩和解压缩速度。</p>

<p>数据压缩和解压缩的本质是通过增加CPU计算时间成本来换取较小的存储成本，以及网络和I/O传输成本。</p>

<p>Snappy是基于LZSS算法的，其整体方案基本遵循LZSS的算法逻辑，LZSS是LZ77的优化方案。</p>

<h5>LZSS算法</h5>

<p>与霍夫曼编码这种统计编码不同，LZ77是一种动态辞典编码（Dictionary Coding）。</p>

<p>词典编码的基本思路是：<strong>文本中的词用它在词典中表示位置的号码代替</strong>的无损数据压缩方式，一般分为静态词典编码和动态词典编码。采用静态词典编码技术时，编码器需要事先构造词典，解码器要事先知道词典。采用动态词典编码技术时，编码器将从未被压缩的文本中自动导出词典，解码器解码时边解码边构造解码词典。</p>

<p>LZ77的压缩算法使用了<strong>滑动窗口</strong>和<strong>前向缓冲区</strong>的概念。</p>

<p><strong>滑动窗口</strong>包含了前面处理过的若干源字符，<strong>前向缓冲区</strong>包含了输入数据流中将要处理的所有后续字符。</p>

<p>算法尝试将前向缓冲区的开始字符串与滑动窗口中的字符串进行最长匹配：</p>

<ul>
	<li>如果没有发现匹配，前向缓冲区的第一个字符输出并且移入滑动窗口，滑动窗口中存在最久的字符被移除</li>
	<li>如果找到匹配字符串，那么匹配字符串作为三元组输出&lt;指针，长度，后续字符&gt;。其中指针指出了匹配字符串在滑动窗口中的起始位置，长度表明匹配字符串的长度，后续字符则指出前向缓冲区中除去匹配字符串后的第一个字符</li>
</ul>

<p>窗口经过这个处理逻辑不断右移就完成了压缩编码过程。</p>

<figure><img src="LZ77%E6%80%9D%E8%B7%AF.jpg"/></figure>

<hr />

<h3>Cuckoo 哈希</h3>

<p>使用Cuckoo哈希可以有效地解决哈希冲突（Hash Collisions）问题。Cuckoo Hash具有很多优良特性，比如可以在O(1)时间复杂度查找和删除数据，可以在常数时间内插入数据，有大约50%的哈希空间利用率。</p>

<h5>基本原理</h5>

<p>传统哈希方法只使用一个哈希函数，为了较好地解决哈希冲突问题，Cuckoo哈希同时使用两个不同的哈希函数$H_1(x)$和$H_2(x)$。</p>

<p>当插入数据时，同时计算$H_1(x)$和$H_2(x)$，如果对应的哈希空间中任意一个桶为空，则可以将x插入相应位置；如果两者都不空，则选择一个桶，将已经占据这个位置的值y踢出去，由x占据这个位置。对于y来说，重复上述过程，知道所有值都找到空桶安置。</p>

<p>对于查找操作来说，只需要查找两个哈希函数映射到的哈希空间对应位置，要么存在要么不存在，是唯一确定的，所以可以在O(1)时间内完成。</p>

<p>与传统哈希方式相比，Cuckoo哈希圣去了当哈希冲突时进行冲突解决的过程，所以查找效率非常高。</p>

</body>
</html>

