<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;</title>
	</head>
<body>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<h1>数据分片与路由</h1>

<p>目前主流大数据存储与计算系统通常采用横向扩展的方式支持系统可扩展性，即通过增加机器数目来获得水平扩展能力。</p>

<p>对于海量数据，通过<strong>数据分片</strong>来将数据进行切分并分配到各个机器，实现系统的水平扩展；数据分片后如何能够找到某条记录的存储位置的问题称为<strong>数据路由</strong>；为了保证数据在环境故障后仍然可用，需要将同一份<strong>数据复制存储</strong>在多处来获得保证。同时数据复制还可以增加读操作的效率，客户端可以从多个备份数据中选择物理距离较近的进行读取，既增加了读操作的并发性又可以提高单次读的读取效率。</p>

<p>常见的数据分片方法包括哈希分片与范围分片。</p>

<hr />

<h3>抽象模型</h3>

<figure><img src="/Users/xerxes/note/bigDataTec/src/%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87%E4%B8%8E%E8%B7%AF%E7%94%B1%E7%9A%84%E6%8A%BD%E8%B1%A1%E6%A8%A1%E5%9E%8B.jpg"/></figure>

<p>如图是一个具有很高抽象级别的数据分片与路由通用模型，可以将其看作是一个二级映射关系。</p>

<p><strong> 数据分片</strong>：第一级映射是<strong>key-partition</strong>映射。其将数据记录映射到数据分片空间，一般是多对一，即一个数据分片包含多条记录数据。第二级映射是<strong>partition-machine</strong>映射，其将数据分片映射到物理机器上，一般也是多对一，即一台物理机器容纳多个数据分片。</p>

<p><strong> 数据路由</strong>：在做数据路由时，比如要查找某条记录的值，首先根据key-partition映射找到对应的数据分片，然后再查找partition-machine关系表，就可以知道存储这条数据的物理机器。</p>

<p>哈希分片与范围分片策略都可以映射到这个抽象模型上，对于哈希分片来说，因为其主要通过哈希函数来建立key-partition映射关系，所以只支持点查询。范围分片的系统既支持点查询也可以支持范围查询。</p>

<h3>哈希分片</h3>

<p>最常见的哈希分片方式有三种：Round Robin，虚拟桶，一致性哈希。</p>

<h5>Round Robin</h5>

<p>俗称哈希取模法。假设有K台物理机，对物理从0到K-1进行编号，对于以key为主键的某个记录，通过 H(key)=hash(key) mod K 来实现数据分片。H(key)的数值即存储该数据的物理机编号。</p>

<p>Round Robin实现简单，但不灵活。如果新增一台物理机，之前已经分配的所有数据和物理机之间的映射要重新计算。</p>

<p>从数据分片与路由通用模型来看，Round Robin其实将物理机和数据分片两个功能点合二为一。即每台物理机对应一个数据分片，这样key-partition和partition-machine映射就两位一体了，都由一个哈希函数来承担，造成了机器个数和映射函数的耦合。</p>

<h5>虚拟桶</h5>

<figure><img src="/Users/xerxes/note/bigDataTec/src/%E8%99%9A%E6%8B%9F%E6%A1%B6%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6.jpg"/></figure>

<p>在待存储记录和物理机之间引入虚拟桶层，所有记录首先通过哈希函数映射到对应的虚拟桶，记录和虚拟桶是多对一的映射关系，即一个虚拟桶包含多条记录信息；第二层映射是虚拟桶和物理机之间的映射关系，也是多对一映射，通过内存表来管理这层映射关系。</p>

<h5>一致性哈希</h5>

<p>分布式哈希表（DHT）是P2P网路和分布式存储中常见的一项技术，是哈希表的分布式扩展，即考虑在多机分布环境，每台机器负责承载部分数据的存储情况下，如何通过哈希方式来对数据进行增/删/改/查等数据操作的方法。DHT只是一个概念，一致性哈希是其中一种实现方式。</p>

<figure><img src="/Users/xerxes/note/bigDataTec/src/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95.jpg"/></figure>

<p>如图是将哈希空间表示为长度为5的二进制数值(m=5)的一致性哈希算法的示意图。因为m=5，所以其哈希空间可以表达的数值范围为0-31，一致性哈希算法将哈希数值空间按照大小组成一个首尾相接的环状序列。</p>

<p>对于每台机器，根据其IP和端口号，经过哈希函数映射到哈希数值空间内，这样不同的机器就变成了环状序列中的不同节点，一台机器负责存储落在一段有序哈希空间内的数据，比如N5节点存储30-31和0-5范围内的键值数据。</p>

<p>同时，每个机器节点记录环中的前驱节点和后继节点地址位置，使之成为一个真正的有向环。</p>

<ol>
	<li>路由问题

		<p>在P2P环境下意味着无中心管理节点，根据数据记录的主键以及哈希函数H来定位到记录内容的方法有如下几种：</p>

		<ul>
			<li>一种方法是沿着有向环顺序查找，接收到查询请求的节点根据哈希函数获得待查找主键的哈希值，判断是否在自身管理范围内，如果不在，则将其转交给后继节点继续查找。</li>
			<li>为了加快查找速度，可以在每个机器节点配置路由表，存储m条路由信息，其中第i项路由信息代表距离当前节点$2^i$的哈希空间数值所在的机器节点编号。

				<p>当机器节点$N_i$接收到主键为key的查询请求，发起初始查询请求，假设当前执行操作的节点$N_c$，$N_c$的后继节点为$N_s$，首先查询主键key对应的键值H(key)=j；然后判断$s<j\leq s$，如果为真，说明key在$N_s$上，$N_c$发送消息给$N_s$，查找key的值value，$N_s$将查询结果返回给$N_i$；否则$N_c$查找其对应的路由表，找到小于j的最大编号节点$N_h$（如果所有路由表都大于j，则选择第m-1项路由信息内的数据作为$N_h$），$N_c$向$N_h$发送消息，请求它代表$N_i$查找key的值value，$N_h$此时成为当前节点$N_c$，继续按照递归地进行查找操作。</p></li>
		</ul></li>
	<li>加入新节点时的情形

		<p>如果P2P网络中新加入一个机器节点$N_new$，首先$N_new$必须能够和目前P2P网路中任意一个节点$N_x$建立联系，通过$N_x$按照上述路由算法查询$N_new$的对应哈希值$H(N_new)=new$，可以找到$N_new$的后继节点$N_s$，假设$N_s$的前驱节点为$N_p$，为了将$N_new$加入P2P网路，需要做两件事：</p>

		<ul>
			<li>改变$N_p$、$N_new$、$N_s$对应已经发生变化的前驱节点和后继节点记录，以体现新的网络架构</li>
			<li>数据的重新分片和分布，具体而言就是将$N_s$节点上存储的应该由$N_new$承载的数据（即$N_s$节点上哈希值小于等于new的记录）迁移到$N_new$节点上。</li>
		</ul>

		<p>在并发环境下，可能有多个新节点要加入，为了保证不出问题，完成上述两步之后还要做两件事：</p>

		<ul>
			<li>将$N_new$的后继节点指向$N_s$，前驱节点置为空值</li>
			<li>这一步称作<strong>稳定性检测</strong>，P2P网路中每个节点会定期执行，通过这一步可以完成前驱和后继的更新和数据迁移。这一步并非专门为新加入节点设立，而是所有节点周期性自动完成。对于节点$N_c$来说，稳定性检测算法流程如下：

				<ol>
					<li>假设$N_s$为$N_c$的后继节点，$N_c$向$N_s$询问其前驱节点$N_p$，$N_s$向$N_c$回复。一般情况下接下来执行第四步</li>
					<li>如果$N_p$介于$N_c$和$N_s$之间，$N_c$记录下$N_p$为其后继节点</li>
					<li>令$N_x$是$N_c$的当前后继节点，其可能是$N_s$也可能是$N_p$，取决于上一步的判断结果。如果$N_x$的前驱节点为空或者$N_c$位于$N_x$和它的前驱节点之间，那么$N_c$给$N_x$发消息说$N_c$就是$N_x$的前驱节点，$N_x$将前驱节点设置为$N_c$</li>
					<li>$N_x$把其部分数据迁移到$N_c$，即$N_x$上哈希值小于等于c的记录。</li>
				</ol></li>
		</ul></li>
	<li>当节点离开P2P网路

		<p>节点离开P2P网路有两种方式：</p>

		<ul>
			<li>正常离开

				<p>正常离开的节点在离开前可以做些准备工作，包括通知相应节点更新其前驱节点和后继节点以及将本身持有数据迁移到后继节点，由于其离开造成的其他机器路由表失效的进行更新。</p></li>
			<li>异常离开

				<p>异常离开往往是机器故障导致，此时故障机器保持的数据可能已经丢失。为了避免这个问题，可以采用将同一份数据在多台机器上保留副本的方式。</p></li>
		</ul></li>
	<li>虚拟节点

		<p>一致性哈希算法有两个潜在问题，机器节点映射到环状结构的位置是随机的，可能导致机器负载不均衡；另外在大规模数据中心中，机器异质性很常见，一致性哈希算法将所有机器平等看待，可能出现低配置机器高负载的情形。</p>

		<p>引入虚拟节点的概念，将一个物理节点虚拟成若干虚拟节点，分别映射到一致性哈希的环状结构不同位置。</p></li>
</ol>

<p>一致性哈希算法将集群机器数从哈希函数中移除，转而将机器及记录主键都映射到哈希数值空间，以此来建立机器与数据记录之间的映射关系，解除机器与数据分布函数之间的直接耦合。</p>

<hr />

<h3>范围分片</h3>

<p>范围分片首先将所有记录的主键进行排序，然后在排好序的主键空间里将记录划分成数据分片，每个数据分片存储有序的主键空间片段内的所有记录。</p>

<p>在实现具体存储系统时，往往保持一个数据分片的映射表，记录表每一项记载数据分片的最小主键及其对应的物理机地址。</p>

<p>在对记录进行操作时，查找映射表就可以找到对应存储这个记录所在数据分片的物理机。</p>

<p>至于数据分片在物理机的管理方式往往采用LSM树，这是一种高效写入的数据索引结构。</p>

<figure><img src="/Users/xerxes/note/bigDataTec/src/%E8%8C%83%E5%9B%B4%E5%88%86%E7%89%87.jpg"/></figure>

</body>
</html>

