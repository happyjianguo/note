<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>Yarn</title>
	</head>
<body>
<h1>Yarn</h1>

<p>YARN是Hadoop2.0的重要组成部分，全称“另一个资源调度器（Yet Another Resource Negotiator）”，是一个独立的资源管理系统。</p>

<p>从资源管理系统范型来看，YARN是个典型的二级调度器，其中RM类似于主控服务器，充当中央调度器的功能。每个任务的AM类似于二级调度器。</p>

<p>AM负责向RM申请作业所需资源，并在作业的众多任务中进行资源分配与协调。</p>

<hr />

<h2>架构</h2>

<figure><img src="/Users/xerxes/note/hadoop/src/YARN%E6%9E%B6%E6%9E%84.jpg"/></figure>

<p>YARN主要构件包括</p>

<ul>
	<li>唯一的资源管理器RM</li>
	<li>每个作业的应用服务器AM</li>
	<li>每个机器一个的节点管理器NM。</li>
</ul>

<p>RM负责全局的资源管理工作，其内部主要功能部件包括：调度器、AM服务器、Client-RM接口以及RM-NM接口。</p>

<p>AM负责向RM申请启动任务所需的资源，同时协调作业内各个任务的运行过程。</p>

<p>NM是YARN中在每台机器上都部署的节点管理器，主要负责机器内容器资源的管理，比如容器间的依赖关系、监控容器执行以及为容器提供资源隔离等各种服务。</p>

<hr />

<h2>运行机制</h2>

<p>Yarn通过两类长期运行的守护进程提供自己的核心服务：管理集群上资源使用的<strong>资源管理器（resource manager，RM）</strong>和运行在集群中所有节点上且能够启动和监控容器的<strong>节点管理器（node manager，NM）</strong>。</p>

<p>另外每个任务都单独有一个<strong>应用服务器（Application Master，AM）</strong>来负责完成任务所需资源的申请管理与任务生命周期管理功能。</p>

<p>容器用于执行特定应用程序的进程，每个容器都有资源限制（内存、CPU等）。一个容器可以是一个Unix进程，也可以是一个Linux cgroup，取决于yarn的配置。</p>

<p>Yarn运行应用的流程：</p>

<figure><img src="/Users/xerxes/note/hadoop/src/yarn%E8%BF%90%E8%A1%8C%E5%BA%94%E7%94%A8%E6%B5%81%E7%A8%8B.jpg"/></figure>

<figure><img src="/Users/xerxes/note/hadoop/src/YARN%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.jpg"/></figure>

<ol>
	<li>客户端联系RM，要求它运行一个AM进程；</li>
	<li>RM找到一个能够在容器中启动AM的NM（AM一旦运行起来后能做些什么依赖于应用本身，有可能是在所处的容器中简单的运行一个计算，并将结果返回给客户端；或是向RM请求更多资源，用于运行一个分布式计算）</li>
	<li>AM负责将作业划分为若干任务，并向RM请求启动任务所需的资源；RM接收到请求后，通过调度器分配资源，找到合适的容器，将这些资源信息返回给AM</li>
	<li>AM根据资源信息，在任务间优化资源分配策略，确定后直接与资源所在的节点管理器联系，在对应的容器中启动任务，节点管理器负责容器的资源隔离</li>
	<li>AM在部分任务执行完成后逐步向RM释放所占资源</li>
</ol>

<h3>资源请求</h3>

<p><strong>当请求多个容器时，可以指定每个容器需要的资源数量，还可以指定对容器的本地限制要求</strong>。</p>

<p>本地化对于确保分布式数据处理算法高效使用集群带宽非常重要，本地限制可用于申请位于指定节点或机架或集群中任何位置的容器。本地限制无法满足时，要么不分配资源，要么放松限制。</p>

<p><strong>当启动一个容器用于处理hdfs数据块</strong>时，应用将会向这样的节点申请容器：存储该数据块三个副本的节点，或是存储这些副本的机架中的一个节点。都失败时，申请任意节点。</p>

<p><strong>Yarn应用可以在运行中的任意时刻提出资源申请</strong>。</p>

<h3>应用生命期</h3>

<p>按照应用到用户运行的作业之间的映射关系对应用进行分类：</p>

<ul>
	<li>一个用户作业对应一个应用</li>
	<li>作业的每个工作流或每个用户对话对应一个应用：这样效率更高，容器可以在作业之间重用，并且有可能缓存作业之间的中间数据</li>
	<li>多个用户共享一个长期运行的应用：这种应用通常是作为一种协调者的角色在运行</li>
</ul>

<hr />

<h2>yarn中的调度</h2>

<h3>调度选项</h3>

<h4>FIFO调度器</h4>

<p>FIFO调度器将应用放置在一个队列中，然后按照提交的顺序运行应用。</p>

<p>优点是简单易懂，不需要任何配置，但是不适合共享集群。</p>

<figure><img src="/Users/xerxes/note/hadoop/src/yarn%20FIFO%E8%B0%83%E5%BA%A6%E5%99%A8.jpg"/></figure>

<p>当使用FIFO调度器时，小作业一直被阻塞，直至大作业完成。</p>

<h4>容量调度器</h4>

<figure><img src="/Users/xerxes/note/hadoop/src/yarn%5C%20%E5%AE%B9%E9%87%8F%E8%B0%83%E5%BA%A6%E5%99%A8.jpg"/></figure>

<p>使用容量调度器时，一个独立的队列保证小作业一提交就可以启动，由于队列容量是为独立队列中的作业保留的，因此这种策略是以整个集群的利用率为代价的。这意味着与FIFO相比，大作业执行的时间更长。</p>

<h4>公平调度器</h4>

<figure><img src="yarn%20%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6%E5%99%A8.jpg"/></figure>

<p>使用公平调度器时，不需要预留一定量的资源，因为调度器会在所有运行的作业之间动态平衡资源。第一个大作业启动时，它也是唯一的作业，因而获得集群所有资源；当第二个小作业启动时，它被分配到集群的一半资源，这样每个作业都能公平共享资源。</p>

<p>第二个作业从启动到获得公平共享资源会有时间滞后，因为它必须等待第一个作业使用的容器用完并释放资源。当小作业结束且不再申请资源后，大作业将回去再次使用全部资源。</p>

<p>这样既得到了较高的资源利用率，又能保证小作业能及时完成。</p>

<h3>容量调度器配置</h3>

<h3>公平调度器配置</h3>

<h3>延迟调度</h3>

<blockquote>
<p>所有yarn调度器都试图以本地请求为重。</p>
</blockquote>

<p>在一个繁忙的集群上，如果一个应用请求某个节点，这个节点很有可能正在运行其他容器。此时如果等待几秒，会增加在所请求的节点上分配到一个容器的机会，从而提高集群的效率。这个特性称为<strong>延迟调度</strong>。容量调度器和公平调度器都支持延迟调度。</p>

<p>Yarn中的每个NM周期性的向RM发送心跳请求，心跳中携带了NM中正在运行的容器、新容器可用的资源等信息，这样对于一个计划运行一个容器的应用而言，每个心跳就是一个潜在的调度机会。</p>

<p>当使用延迟调度时，调度器不会简单的使用它收到的第一个调度机会，而是等待设定的最大数目的调度机会发生，然后才放松本地性限制并接收下一个调度机会。</p>

<h3>主导资源公平性</h3>

<p>当应用需要多种资源类型时，应用与应用之间很难比较。</p>

<p>Yarn中调度器解决此问题的思路是：观察每个用户的主导资源，并将其作为对集群资源使用的一个度量。这个方法称为<strong>主导资源公平性（Dominant Resource Fairness，DRF）</strong>。</p>

<p>举例：</p>

<p>某集群有100个CPU和10TB内存。应用A请求2个CPU和300GB内存，应用B请求6个CPU和100GB内存。</p>

<p>A请求的资源在集群中占比分别为2%，3%，因此内存是A的主导资源；B请求的资源在集群中占比分别为6%，%1，因此CPU是B的主导资源。</p>

<p>B的主导资源是A的两倍，因此在公平调度下，B将分到一半的容器数。</p>

</body>
</html>

