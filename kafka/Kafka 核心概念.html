<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>Kafka 核心概念</title>
	</head>
<body>
<h1>Kafka 核心概念</h1>

<hr />

<h2>生产者Producer</h2>

<p>生产者的主要工作是生产消息，并将消息按照一定的规则推送到Topic的分区中。</p>

<hr />

<h2>消费者Consumer</h2>

<p>消费者的主要工作是从Topic中拉取消息，并对消息进行消费。</p>

<p>某个消费者消费到Partition的offset，是Consumer自己维护的。</p>

<hr />

<h2>消费者组Consumer Group</h2>

<p>多个Consumer组成一个Consumer Group，一个Consumer只能属于一个Consumer Group。</p>

<p><strong>Consumer Group保证订阅的Topic的每个分区只能被分配给这个Group中 的一个消费者处理</strong>。</p>

<p>如果不同Consumer Group订阅了同一个Topic，Group之间批次不干扰。如果要实现一个消息可以被多个Consumer同时消费，要将每个消费者放入单独的Consumer Group；如果要实现一个消息只能被一个Consumer消费，则将所有的Consumer放入一个Consumer Group。</p>

<p><strong>Kafka还通过Consumer Group实现了消费者的水平扩展和故障转移</strong>。</p>

<ul>
	<li>当一个Consumer的处理能力不足以处理多个Partition，通过向Consumer Group添加消费者，出发Rebalance操作重新分配Partition与Consumer的对应关系，从而实现水平扩展</li>
	<li>当一个Consumer宕机时，Consumer Group自动重新分配分区</li>
</ul>

<p>Consumer Group中的Consumer的数量并不是越多越好，当Consumer数量超过分区的数量时，会有消费者分配不到分区。</p>

<hr />

<h2>消息</h2>

<p>消息是Kafka中最基本的数据单元。消息由一串子节构成，其中主要有key和value构成，key和value也都是byte数组。</p>

<p>Key的主要作用是根据一定的策略，将此消息路由到指定的分区中，这样就可以保证包含同一key的消息全部写入同一分区中。key可以是null。</p>

<p>消息的真正有效负载是value部分的数据。为了提高网络和存储的利用率，<strong>生产者会批量发送消息到Kafka，并在发送之前对消息进行压缩</strong>。</p>

<hr />

<h2>Topic、partition、Log、Segment</h2>

<p>Topic是用于存储消息的逻辑概念，可以看作一个消息集合。每个Topic可以有多个生产者向其中推送消息，可以有任意多个消费者消息其中的消息。</p>

<p><strong>每个Topic可以划分成多个分区</strong>，同一个Topic下的不同分区包含的消息是不同的。</p>

<p><strong>每个消息在被添加到分区时都会被分配一个offset</strong>，它是消息在此分区中的唯一编号，Kafka通过offset保证消息在分区内的顺序。</p>

<p><strong>同一个Topic的不同分区会分配在不同的Broker上</strong>。分区是Kafka水平扩展性的基础，通过增加服务器并在其上分配Partition的方式来增加Kafka的并行处理能力。</p>

<p><strong>分区在逻辑上对应着一个Log，当生产者将消息写入分区时，实际上是写入到了分区对应的Log</strong>。Log是一个逻辑概念，可以对应到磁盘上的一个文件夹。<strong>Log由多个Segment组成，每个Segment对应一个日志文件和索引文件</strong>。在面对海量数据时，为避免出现超大文件，每个日志文件的大小有限制，超出限制就创建新的Segment。</p>

<p>因为<strong>Kafka采用顺序I/O，所以只会向最新的Segment追加数据</strong>。为了权衡文件大小、索引速度、占用内存大小等多方面因素，<strong>索引文件采用稀疏索引的方式</strong>，大小并不会很大，在运行时会将其内容映射到内存，提高索引速度。</p>

<hr />

<h2>副本</h2>

<p><strong>Kafka对消息进行了冗余备份，每个Partition可以有多个副本</strong>。</p>

<p>每个分区的副本集合中，都会选举出一个副本作为Leader副本，Kafka在不同的场景下采用不同的选举策略。<strong>所有读写请求都由Leader副本处理，Follower副本仅仅从Leader副本处把数据拉取到本地，同步更新到自己的Log中</strong>。通常同一分区的多个副本会被分配到不同的Broker上。</p>

<hr />

<h2>保留策略（Retention Policy）、日志压缩（Log Compaction）</h2>

<p><strong>无论消费者是否已经消费了消息，Kafka都会一直保存这些消息，然后根据保留策略周期性地删除旧消息</strong>。保留策略有两种：</p>

<ul>
	<li>根据消息保留的时间，当消息在Kafka中保存的时间超过了指定时间，就可以被删除</li>
	<li>根据Topic存储的数据大小，当Topic所占的日志文件大小大于一个阈值，则可以开始删除最旧的消息</li>
</ul>

<p>Kafka会启动一个后台线程，定期检查是否存在可以删除的消息。保留策略的配置非常灵活，可以有全局的配置，也可以针对Topic进行配置覆盖全局配置。</p>

<p>很多场景下消息的key与value的值之间的对应关系是不断变化的，消费者只关心key对应的最新value值。<strong>Kafka的日志压缩功能会在后台启动一个线程，定期将相同key的消息进行合并，只保留最新的value值</strong>。</p>

<figure><img src="/Users/xerxes/note/kafka/src/Kafka%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9.jpg"/></figure>

<hr />

<h2>Broker</h2>

<p>一个单独的Kafka server就是一个Broker。Broker的主要工作就是接收生产者发过来的消息，分配offset，保存到磁盘；同时接收消费者、其他Broker的请求，根据请求类型进行相应处理并返回响应。</p>

<hr />

<h2>Cluster、Controller</h2>

<p><strong>多个Broker可以做成一个Cluster对外提供服务，每个Cluster当中会选举出一个Broker来担任Controller，Controller是Kafka集群的指挥中心，而其他Broker则听从Controller指挥实现相应的功能</strong>。</p>

<p>Controller负责将分区分配给broker、管理分区的状态、每个分区的副本状态、监听ZooKeeper中数据的变化等工作。</p>

<p>Controller也是一主多从的实现，所有Broker都会监听Controller Leader的状态，当Leader Controller出现故障时重新选举Controller Leader。</p>

<hr />

<h2>ISR集合</h2>

<p>ISR（In-Sync Replica）集合表示的是<strong>目前可用且消息量与Leader相差不多的副本集合</strong>。</p>

<p><strong>只有这个集合中的replica 才能被选举为leader，也只有该集合中所有replica 都接收到了同一条消息，Kafka才会将该消息置为“已提交”状态，即认为该消息发送成功</strong>。</p>

<p>Kafka承若只要这个集合中至少存在一个replica，那些“已提交”状态的消息就不会丢失。</p>

<p>ISR集合中的副本必须满足两个条件：</p>

<ul>
	<li>副本所在节点必须维持着与ZooKeeper 的连接</li>
	<li>副本最后一条消息的offset 与Leader 副本的最后一条消息的offset 之间的差值不能超出指定的阈值</li>
</ul>

<p><strong>每个分区的Leader 副本都会维护此分区的ISR 集合。写请求首先由Leader 副本处理，之后Follower 副本会从Leader 上拉取写入的消息</strong>，这个过程有延迟，导致Follower副本中保存的消息略少于Leader 副本。</p>

<p>当落后到一定程度时，Kafka会将这些replica移出ISR；当replica重新追上leader的进度时，Kafka会将这些replica加回到ISR。</p>

<hr />

<h2>HW、LEO</h2>

<p>HW（HighWatermark）和LEO（Log End Offset）与上面的ISR集合紧密相关。</p>

<p><strong> HW 也是由Leader 副本管理的 。HW 标记了一个特殊的offset，当消费者处理消息的时候，只能拉取到HW 之前的消息</strong>，HW之后的消息对消费者来说是不可见的。与ISR 集合类似。<strong>当ISR 集合中全部的Follower 副本都拉取HW 指定消息进行同步后，Leader 副本会递增HW 的值</strong>。</p>

<p><strong>LEO 是所有的副本都会有的一个offset 标记，它指向追加到当前副本的最后一个消息的offset</strong>。当生产者向Leader 副本追加消息的时候，Leader 副本的LEO标记会递增；当Follower 副本成功从Leader 副本拉取消息并更新到本地的时候，Follower 副本的LEO 增加。</p>

<hr />

<h2>ISR集合、HW和LEO如何协调工作</h2>

<ol>
	<li>Producer向此Partition推送消息；</li>
	<li>Leader副本将消息追加到Log，并递增LEO；</li>
	<li>Follower副本从Leader拉取消息进行同步；</li>
	<li>Follower副本将拉取到的消息更新到本地Log，并递增其LEO；</li>
	<li>当ISR 集合中所有副本都完成了offset=x 的消息的同步，Leader副本递增HW；</li>
	<li>至此offset=x 的消息对生产者可见</li>
</ol>

<hr />

<h2>总结</h2>

<figure><img src="/Users/xerxes/note/kafka/src/Kafka%E7%94%9F%E4%BA%A7%E6%B6%88%E8%B4%B9.jpg"/></figure>

<ol>
	<li>生产者根据业务逻辑产生消息，根据路由规则将消息发送到指定分区的Leader 副本所在的Broker；</li>
	<li>Kafka server 收到消息，将消息追加到Log 中保存；</li>
	<li>Follower 副本与Leader 副本进行同步，当ISR 集合中所有副本都完成了此消息的同步，Leader 副本的HW 增加，并向生产者返回响应</li>
</ol>

</body>
</html>

