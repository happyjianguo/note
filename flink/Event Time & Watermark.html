<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>Event Time &amp; Watermark</title>
	</head>
<body>
<h1>Event Time &amp; Watermark</h1>

<hr />

<h2>Event Time</h2>

<p>Event-Time 是用事件真实产生的时间戳去做Re-bucketing，把对应时间3-4点的数据放在3-4点的Bucket，然后Bucket产生结果。如下图所示Event-Time 和Processing-Time 之间有一个对比。</p>

<figure><img src="/Users/xerxes/note/flink/src/processing:event%5C%20time%E5%AF%B9%E6%AF%94.jpg"/></figure>

<p><strong>Event-Time 的重要性在于记录引擎输出运算结果的时间</strong>。当流式引擎连续24小时在运行，假设Pipeline 里有一个windows Operator 正在做运算，每小时能产生结果，何时输出windows 的运算值，这个时间点就是Event-Time 处理的精髓，用来表示该收的数据已经收到。</p>

<hr />

<h2>Watermark</h2>

<p>假设有这样一个带有时间戳的事件流，其中的事件并不是按顺序到达的，图中的数字代表事件发生的时间戳：</p>

<figure><img src="/Users/xerxes/note/flink/src/event-stream%E7%A4%BA%E4%BE%8B.jpg"/></figure>

<p>对这个事件流处理时会有几个问题：1. 流中第一个元素的时间是4，但是不能直接将它作为排序后数据流的第一个元素并输出它，因为数据是乱序的，也许有一个更早发生的事件还没有到；2. 时间是4的元素到了之后，时间是2的元素也到了，但是我们不知道还有没有事件时间更早的事件。</p>

<p>为了确定何时停止等待更早的数据的到来，就需要用到Watermark。<strong>Watermark 定义了何时不再等待更早的数据</strong>。</p>

<p>Watermark 是一种特殊的带有时间戳的元素，Flink 中的事件时间处理依赖于Watermark。它们由数据源或者Watermark 生成器插入数据流中。<strong>具有时间戳t 的Watermark 可以理解为：确定了所有时间戳小于等于t 的事件都（在某种合理的概率上）已经到达了</strong>。</p>

<p>回到例子中，当收到时间戳大于等于2的Watermark 时，就会将事件时间为2的事件作为首个元素输出。</p>

<hr />

<h2>Time Characteristic</h2>

<p>为了使用event time，流处理程序需要设置一下time characteristic：</p>

<pre><code>final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
</code></pre>

<p>另外程序还需要使用直接为数据定义了event time 并且发出watermarks 的数据源，或者程序在接收数据源后注入Timestamp Assigner &amp; Watermark Generator。这些函数描述了如何访问event timestamps，以及event streams 的乱序程度。</p>

<hr />

<h2>分配timestamps</h2>

<p>为了使用event time，Flink 需要知道事件的timestamp，流数据中的每一个元素都需要分配一个timestamp，这通常由从数据源的某些字段中accessing/extracting 出timestamp 来完成。</p>

<p>分配timestamp 和生成watermark 关系密切，后者会告诉系统event time 的进展。</p>

<p><strong>Flink 有两种分配timestamp 和生成watermark 的方式</strong>：</p>

<ul>
	<li>直接在数据流源头生成；</li>
	<li>通过timestamp assigner/watermark generator</li>
</ul>

<p><strong>Flink 生成watermark 的方式有两种</strong>：</p>

<ul>
	<li>With Periodic Watermarks；</li>
	<li>With Punctuated Watermarks</li>
</ul>

<p>这两种方式的区别在于如何调用<code>getWatermark</code>方法。</p>

<h3>Source Functions with Timestamps and Watermarks</h3>

<p>数据流源头可以直接给他们产生的元素分配timestamp，也可以发出watermarks。</p>

<p>此时不需要在后面再设定timestamp assigner，如果设置了，会覆盖数据源自己设置的timestamps 和watermarks。</p>

<p>如下代码所示source function 如何分配timestamp 和生成watermark：</p>

<pre><code>@Override
public void run(SourceContext&lt;MyType&gt; ctx) throws Exception {
	while (/* condition */) {
		MyType next = getNext();
		ctx.collectWithTimestamp(next, next.getEventTimestamp());

		if (next.hasWatermarkTime()) {
			ctx.emitWatermark(new Watermark(next.getWatermarkTime()));
		}
	}
}
</code></pre>

<p>通过<code>collectWithTimestamp</code>方法发送一条数据，第一个参数是要发送的数据，第二个参数是这个数据对应的时间戳。</p>

<p>通过<code>emitWatermark</code>方法发出一条watermark。</p>

<h3>Timestamp Assigners / Watermark Generators</h3>

<p><strong>Timestamp assigners 拿到一个stream，然后生成一个包含带有timestamp 的元素和watermark 的新的stream</strong>。如果之前的stream 有timestamp 或者watermark，则覆盖之。</p>

<p>Timestamp assigners 通常可以在数据源后面指定，但不是必须指定，例如常见的模式是在parse（MapFunction）和filter（FilterFunction）后面指定timestamp assigners。</p>

<p>任何情况下，<strong>timestamp assigner 都需要在第一个event time 的operation（如第一个window operation）之前指定</strong>。</p>

<p>特殊情况下，使用Kafka 作为流处理程序的数据源时，Flink 允许在source 内指定timestamp assigner/watermark emitter。</p>

<p>如下代码展示了创建timestamp extractors/watermark emitters 必须实现的接口：</p>

<pre><code>final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

DataStream&lt;MyEvent&gt; stream = env.readFile(
        myFormat, myFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, 100,
        FilePathFilter.createDefaultFilter(), typeInfo);

DataStream&lt;MyEvent&gt; withTimestampsAndWatermarks = stream
        .filter( event -&gt; event.severity() == WARNING )
        .assignTimestampsAndWatermarks(new MyTimestampsAndWatermarks());

withTimestampsAndWatermarks
        .keyBy( (event) -&gt; event.getGroup() )
        .timeWindow(Time.seconds(10))
        .reduce( (a, b) -&gt; a.add(b) )
        .addSink(...);
</code></pre>

<h3>With Periodic Watermarks</h3>

<p><code>AssignerWithPeriodicWatermarks</code>周期性的分配timestamps 和生成watermarks（可能依赖于流数据的元素，或者纯粹基于processing time）。</p>

<p>生成watermark 的间隔是通过<code>ExecutionConfig.setAutoWatermarkInterval(...)</code>来定义的。</p>

<p>每次调用assigner 的<code>getCurrentWatermark()</code>方法，如果返回的watermark 非空并且比之前的watermark 大，就会产生一条新的watermark。 </p>

<p>如下代码所示是周期性生成watermark 的例子：</p>

<pre><code>/**
 * This generator generates watermarks assuming that elements arrive out of order,
 * but only to a certain degree. The latest elements for a certain timestamp t will arrive
 * at most n milliseconds after the earliest elements for timestamp t.
 */
public class BoundedOutOfOrdernessGenerator implements AssignerWithPeriodicWatermarks&lt;MyEvent&gt; {

    private final long maxOutOfOrderness = 3500; // 3.5 seconds

    private long currentMaxTimestamp;

    @Override
    public long extractTimestamp(MyEvent element, long previousElementTimestamp) {
        long timestamp = element.getCreationTime();
        currentMaxTimestamp = Math.max(timestamp, currentMaxTimestamp);
        return timestamp;
    }

    @Override
    public Watermark getCurrentWatermark() {
        // return the watermark as current highest timestamp minus the out-of-orderness bound
        return new Watermark(currentMaxTimestamp - maxOutOfOrderness);
    }
}
</code></pre>

<h3>With Punctuated Watermarks</h3>

<p>数据驱动，根据特殊记录生成watermark，即当看到一些特殊的记录就表示接下来可能不会有符合条件的数据再发过来了，此时每当为一个事件分配tiemstamp，都会调用用户实现的生成watermark 的方法。</p>

<p>当一个事件表明可能生成watermark 的时候，可以使用<code>AssignerWithPunctuatedWatermarks</code>来生成watermark。</p>

<p>对于这个class，Flink 首先会调用<code>extractTimestamp(...)</code>方法给元素分配timestamp，然后立刻在这个元素上调用<code>checkAndGetNextWatermark(...)</code>方法，这个方法接收<code>extractTimestamp(...)</code>方法分配的timestamp，然后决定是否生成watermark。</p>

<p>无论何时<code>checkAndGetNextWatermark(...)</code>方法返回一个非空的watermark，并且watermark 大于最近的watermark，就会产生新的watermark。</p>

<pre><code>public class PunctuatedAssigner implements AssignerWithPunctuatedWatermarks&lt;MyEvent&gt; {

	@Override
	public long extractTimestamp(MyEvent element, long previousElementTimestamp) {
		return element.getCreationTime();
	}

	@Override
	public Watermark checkAndGetNextWatermark(MyEvent lastElement, long extractedTimestamp) {
		return lastElement.hasWatermarkMarker() ? new Watermark(extractedTimestamp) : null;
	}
}
</code></pre>

<p>这有可能会为每一个事件都生成一个watermark，每个watermark 都会导致下游的计算，会影响性能。</p>

<h3>预定义Timestamp Extractors / Watermark Emitters</h3>

<p>Flink 还提供了一些pre-implemented 的timestamp assigners。</p>

<h4>Assigners with ascending timestamps</h4>

<p>Periodic watermark generation 最简单的特殊情况是数据源任务的timestamp 升序出现。这种情况下，当前timestamp 总是能作为watermark，因为不会出现更早的timestamp。</p>

<pre><code>DataStream&lt;MyEvent&gt; stream = ...

DataStream&lt;MyEvent&gt; withTimestampsAndWatermarks =
    stream.assignTimestampsAndWatermarks(new AscendingTimestampExtractor&lt;MyEvent&gt;() {

        @Override
        public long extractAscendingTimestamp(MyEvent element) {
            return element.getCreationTime();
        }
});
</code></pre>

<h4>Assigners allowing a fixed amount of lateness</h4>

<p>另一个periodic watermark generation 的例子是当watermark 以一段固定时间滞后于在stream 中能看到的最大的event time。</p>

<p>Flink 提供了<code>BoundedOutOfOrdernessTimestampExtractor</code>，它接收一个参数<code>maxOutOfOrderness</code>，即允许元素迟到的最大时长，超过时长则忽略元素计算窗口内数据。</p>

<p>Lateness 对应于<code>t - t_w</code>的结果，<code>t</code>是元素的tiemstamp，<code>t_w</code>是之前的watermark。如果<code>lateness &gt; 0</code>则元素视为迟到，默认情况下计算窗口数据时忽略此元素。</p>

<pre><code>DataStream&lt;MyEvent&gt; stream = ...

DataStream&lt;MyEvent&gt; withTimestampsAndWatermarks =
    stream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor&lt;MyEvent&gt;(Time.seconds(10)) {

        @Override
        public long extractTimestamp(MyEvent element) {
            return element.getCreationTime();
        }
});
</code></pre>

<hr />

<h2>Timestamps per Kafka Partition</h2>

<p>使用Kafka 作为数据源时，每个Kafka 的分区都有自己的时间模式。但是当并行消费Kafka 中多个分区的数据流时，会打乱事件的顺序。</p>

<p>这种情况下，可以使用Flink 的<code>Kafka-partition-aware</code>watermark generation。利用这个特性，watermark 会在Kafka consumer 内生成。每个partition和每个partition 的watermark 会按照与watermark 在stream 中同样的方式合并。</p>

<p>如下代码展示了如何使用<code>Kafka-partition-aware</code>watermark generation：</p>

<pre><code>FlinkKafkaConsumer09&lt;MyType&gt; kafkaSource = new FlinkKafkaConsumer09&lt;&gt;(&quot;myTopic&quot;, schema, props);
kafkaSource.assignTimestampsAndWatermarks(new AscendingTimestampExtractor&lt;MyType&gt;() {

    @Override
    public long extractAscendingTimestamp(MyType element) {
        return element.eventTimestamp();
    }
});

DataStream&lt;MyType&gt; stream = env.addSource(kafkaSource);
</code></pre>

<p>如下图展示了watermark 如何在数据流中传播：</p>

<figure><img src="/Users/xerxes/note/flink/src/watermark%E5%9C%A8Kafka%5C%20source%E4%B8%AD%E6%B5%81%E5%8A%A8.jpg"/></figure>

<hr />

<h2>迟到事件</h2>

<p>迟到事件是乱序事件的特例，和一般乱序事件不同的是它们的乱序程度超过了watermark，导致窗口在它们到达之前就关闭了。</p>

<p>迟到事件出现时窗口已经关闭并且产生了计算结果，因此处理方法有三种：</p>

<ul>
	<li>将迟到事件收集起来另做处理；</li>
	<li>重新激活已经关闭的窗口并重新计算以修正结果；</li>
	<li>将迟到事件视为错误消息并丢弃</li>
</ul>

<p>Flink 默认处理方式是第三种，其他两种方式分别使用<code>Side Output</code>和<code>Allowed Lateness</code>。</p>

<h3>Side Outputs</h3>

<p>除了DataStream 操作产生的主Stream 之外，还可以产生任意数量的附加的side outputs。</p>

<p>在使用side outputs 时，首先要定义一个<code>OutputTag</code>来标识一个side output stream：</p>

<pre><code>OutputTag&lt;String&gt; outputTag = new OutputTag&lt;String&gt;(&quot;side-output&quot;) {};
</code></pre>

<p>可以通过如下函数将数据发出到side output：</p>

<ul>
	<li>ProcessFunction；</li>
	<li>KeyedProcessFunction；</li>
	<li>CoProcessFunction；</li>
	<li>KeyedCoProcessFunction；</li>
	<li>ProcessWindowFunction；</li>
	<li>ProcessAllWindowFunction</li>
</ul>

<p>可以使用上述函数中暴露给用户的环境变量来将数据发出到OutputTag 标识的side output 中。如下代码示例：</p>

<pre><code>DataStream&lt;Integer&gt; input = ...;
final OutputTag&lt;String&gt; outputTag = new OutputTag&lt;String&gt;(&quot;side-output&quot;) {};
SingleOutputStreamOperatir&lt;Integer&gt; mainDataStream = input.process(new ProcessFunction&lt;Integer, Integer&gt;() {
    @Override
    public void processElement(
        Integer value,
        Context ctx,
        Collector&lt;Integer&gt; out) throws Exception {
        // 将数据发出到常规output
        out.collect(value);
        // 将数据发出到side output
        ctx.output(outputTag, &quot;sideout-&quot; + String.valueOf(value));
    }
});
</code></pre>

<p>可以利用该机制将迟到事件单独放入一个数据流分支，作为window 计算结果的副产品，以便用户获取并对其进行处理。</p>

<pre><code>DataStream&lt;T&gt; input = ...;
final OutputTag&lt;T&gt; outputTag = new OutputTag&lt;T&gt;(&quot;late-data&quot;) {};
SingleOutputStreamOperator&lt;T&gt; result = input
    .keyBy(&lt;key selector&gt;)
    .window(&lt;window assigner&gt;)
    .allowedLateness(&lt;time&gt;)
    .sideOutputLateData(lateOutputTag)
    .&lt;windowed transformation(&lt;window function&gt;)&gt;;
DataStream&lt;T&gt; lateStream = result.getSideOutput(lateOutputTag);
</code></pre>

<h3>Allowed Lateness</h3>

<p>Flink 允许为window operators 指定一个最大迟到时间，表示元素可以迟到多久之后被丢弃。其默认值为0。</p>

<p>元素在watermark 超过end of the window 之后，end of the window + allowed lateness 之前到达，就会在它所属的window 中进行计算。</p>

<p>该机制依赖于trigger，一个迟到但是未被丢弃的元素会引发window 的重新计算。这就是EventTimeTrigger 的情况。</p>

<p>为了确保机制可用，Flink 会保存windows 的state 直到该window 的allowed lateness 失效。一旦失效，Flink 会移除window 并删除它的state。</p>

<p>因为保存窗口状态需要额外内存，并且如果窗口计算使用了ProcessWindowFunction API 还可能使得每个迟到事件触发一次窗口的全量计算，代价较大，所以允许迟到时长不宜设置过长，迟到事件不宜过多，否则应该考虑降低watermark 提高的速度，或者调整算法。</p>

<p>可以用如下代码示例的方式指定allowed lateness：</p>

<pre><code>DataStream&lt;T&gt; input = ...;
input.
    keyBy(&lt;key selector&gt;)
    window(&lt;window assigner&gt;)
    allowedLateness(&lt;time&gt;)
    &lt;windowed transformation(&lt;window function&gt;)&gt;;
</code></pre>

</body>
</html>

